import pandas as pd
import numpy as np
import joblib
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder

# âœ… Load the existing trained model and label encoders (if available)
try:
    model = joblib.load("farm_ai_model.pkl")
    label_enc_crop = joblib.load("crop_type_encoder.pkl")
    label_enc_action = joblib.load("action_encoder.pkl")
    print("âœ… Existing model and encoders loaded successfully!")
except FileNotFoundError:
    print("âš ï¸ No existing model found. Training a new model instead.")
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    label_enc_crop = LabelEncoder()
    label_enc_action = LabelEncoder()

print("\nClass distribution before train-test split:\n", new_data["recommendation"].value_counts())

# âœ… Load new data (Replace 'new_farm_data.csv' with your actual file)
try:
    new_data = pd.read_csv("new_farm_data.csv")
print("\nğŸ” First 5 rows of loaded data:\n", new_data.head())
print("\nğŸ” Dataset shape:", new_data.shape)

    print("âœ… New data loaded successfully!")
except FileNotFoundError:
    print("âŒ Error: The file 'new_farm_data.csv' was not found.")
    exit()

print(f"âœ… Number of training samples: {len(X_train)}")
print(f"âœ… Number of features: {X_train.shape[1]}")

# âœ… Ensure the dataset contains required columns
required_columns = ["humidity", "temperature", "water_level", "soil_moisture", "acidity", "crop_type", "recommendation"]
if not all(col in new_data.columns for col in required_columns):
    print("âŒ Error: The dataset is missing required columns!")
    exit()

# âœ… Encode categorical features (Crop Type & Recommendation)
new_data["crop_type"] = label_enc_crop.fit_transform(new_data["crop_type"])
new_data["recommendation"] = label_enc_action.fit_transform(new_data["recommendation"])

# âœ… Check Class Distribution
print("\nClass distribution before train-test split:\n", new_data["recommendation"].value_counts())

# âœ… Use StratifiedShuffleSplit to Ensure Balanced Train-Test Split
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)

for train_index, test_index in sss.split(new_data.drop(columns=["recommendation"]), new_data["recommendation"]):
    X_train, X_test = new_data.drop(columns=["recommendation"]).iloc[train_index], new_data.drop(columns=["recommendation"]).iloc[test_index]
    y_train, y_test = new_data["recommendation"].iloc[train_index], new_data["recommendation"].iloc[test_index]

print(f"âœ… Training samples: {len(X_train)}, Testing samples: {len(X_test)}")

# âœ… Retrain the model with additional estimators
model.n_estimators += 50  # Increase trees for better learning
model.fit(X_train, y_train)
print("âœ… Model retraining complete!")

# âœ… Evaluate accuracy
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"ğŸ¯ Updated Model Accuracy: {accuracy * 100:.2f}%")

# âœ… Display classification report and confusion matrix
print("\nUpdated Classification Report:\n", classification_report(y_test, y_pred))
print("\nUpdated Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# âœ… Save the updated model and encoders
joblib.dump(model, "farm_ai_model_updated.pkl")
joblib.dump(label_enc_crop, "crop_type_encoder.pkl")
joblib.dump(label_enc_action, "action_encoder.pkl")

print("âœ… Updated model and encoders saved successfully!")

